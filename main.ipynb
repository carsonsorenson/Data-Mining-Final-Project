{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VptWLgfksmng"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FXurxrmRtF_A"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkSmuwzzuZf2"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoN_GbbJt8bz"
   },
   "source": [
    "### Quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "nUVsIvbRtIOX",
    "outputId": "434f6c14-8ccd-4852-d505-28b20bfe5b4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH_uiHwduBAX"
   },
   "source": [
    "### Example of a Normal Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "NrMrlFngtj1d",
    "outputId": "af7c7d4c-6e77-4d80-8123-ca9f76051003"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['target'] == 0][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_VfdK48uTbT"
   },
   "source": [
    "### Example of Disaster Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "BfsFdoT2uGeZ",
    "outputId": "bf47c20d-e8cf-4bd4-a4e1-790660955cdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 1][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQNuEe2AvMUE"
   },
   "source": [
    "### Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "p5M5JcLquYco",
    "outputId": "b13f971b-cc1c-47ef-f621-cb46d0908128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = train_df.target.value_counts()\n",
    "values = [dist[0], dist[1]]\n",
    "names = [\"Normal Tweet\", \"Disaster Tweet\"]\n",
    "plt.figure()\n",
    "plt.title(\"Data Distribution of Training Data\")\n",
    "plt.bar(names, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9pdKL33wzBw"
   },
   "source": [
    "# Simple Vectorizor\n",
    "\n",
    "For the first method, just take the data and use sklearn's CountVectorizer to convert the documents into a vector. Then use logistic regression to make a prediction. This should give us a baseline of our performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cFrDOP2fwydI"
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjFu0Sg8vfG8",
    "outputId": "225cbf5f-4248-4cd7-e522-6e09e6883265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 21637)\n",
      "(3263, 21637)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = feature_extraction.text.CountVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_df[\"text\"])\n",
    "test_vectors = vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "print(train_vectors.shape)\n",
    "print(test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cca1hUixeqa",
    "outputId": "fc9575c6-923a-4fdc-95bd-aa17a18da34b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zx6Qfkp_x4_j",
    "outputId": "a892b617-a9cd-4b27-a4d3-759a2d680861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9675554971758834\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy on the training data\n",
    "\n",
    "train_preds = model.predict(train_vectors)\n",
    "train_acc = accuracy_score(train_df[\"target\"], train_preds)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lo-2mbb2yPDy"
   },
   "outputs": [],
   "source": [
    "# save the predictions on the testing data to submit to kaggle\n",
    "\n",
    "df = pd.DataFrame()\n",
    "test_preds = model.predict(test_vectors)\n",
    "df[\"id\"] = test_df[\"id\"]\n",
    "df[\"target\"] = test_preds\n",
    "df.to_csv(\"logistic_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJMBCiPF2Wqt"
   },
   "source": [
    "Nice! That already gets us a score of 0.79987."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLhZj1sKKOAt"
   },
   "source": [
    "# Better Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T0K-4o5Ne_m"
   },
   "source": [
    "### I Implemented the following preprocessing steps\n",
    "\n",
    "* Remove URLs\n",
    "* Convert to Lowercase\n",
    "* Remove Punctuation\n",
    "* Remove Stop Words\n",
    "\n",
    "\n",
    "### Some more ideas we could try\n",
    "* Add spellchecker (tried implementing with pyspellchecker, but processing took too long)\n",
    "* Do something with the emoji's\n",
    "* Convert abbreviations to phrases. For example lol to laugh out loud, etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7aNgNG8ZPoRp",
    "outputId": "1ec94735-ec72-4c08-d89e-387fa48d87c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXdW0r8NPp9B",
    "outputId": "a53a4510-61d6-46b5-dc2e-954569259793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you', \"you're\", 'hadn', 'yourself', 'while', 'after', 'your', 'all', 'an', 'had', 'on', 'to', \"weren't\", \"didn't\", 'by', 'can', 'above', 'won', 'we', 'wasn', 'nor', 'not', 'am', \"mustn't\", 'mightn', 'about', 'no', 'a', \"needn't\", 'there', 'didn', 'very', 'hasn', 've', 'wouldn', \"it's\", 'are', 'over', 'of', 'whom', 'against', 'our', 'where', 'most', 'being', \"haven't\", 'do', 'further', 'few', 'and', 'itself', 'then', 'than', \"hadn't\", 'aren', \"isn't\", 'shouldn', 'been', 'out', 'having', \"aren't\", 'through', \"hasn't\", 'how', 'other', 'himself', 'at', 'more', 'just', 'd', 'were', 'this', \"she's\", 'too', 'was', 'yours', \"that'll\", 'my', 'or', 'isn', \"you'd\", 'will', 'once', 'doesn', 'she', 'mustn', 't', 'between', 'why', \"won't\", 'ours', 'any', \"mightn't\", 'its', 'own', 'll', \"shan't\", 'that', 'myself', 'but', 'because', 'which', 'so', 'yourselves', \"should've\", 'don', 'again', 'for', 'each', 're', 'under', 'him', 'off', \"wouldn't\", 'the', 'theirs', 'until', 'be', 'up', 'he', 'them', 'me', 'they', 'it', 'what', 'as', 'themselves', 'shan', 'such', 'i', 'haven', 'into', 'those', 'if', 'has', 'is', \"you'll\", 'who', 'now', 'does', 'here', 'weren', 'with', 'have', 'did', 'only', 'in', \"don't\", 'needn', 'should', 'before', \"couldn't\", 'doing', 's', 'down', 'ain', 'their', 'both', 'ma', 'when', 'during', \"you've\", 'o', \"shouldn't\", 'from', 'm', 'herself', 'couldn', \"doesn't\", \"wasn't\", 'same', 'hers', 'these', 'his', 'some', 'her', 'ourselves', 'below', 'y'}\n"
     ]
    }
   ],
   "source": [
    "STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTkDNxuTUbFB"
   },
   "source": [
    "### URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CQkzHyUjUVcG"
   },
   "outputs": [],
   "source": [
    "# thanks to https://stackoverflow.com/questions/6038061/regular-expression-to-find-urls-within-a-string for the robust regex\n",
    "url_re = re.compile(r'(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])?')\n",
    "def remove_url(text):\n",
    "    text = url_re.sub('', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWAkxhQXUXKN",
    "outputId": "d5e2a041-e5c3-42ce-b915-0b88093f695d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop the Annihilation of the Salt River Wild Horses!  via @Change\n"
     ]
    }
   ],
   "source": [
    "# got this example straight from the training data\n",
    "example = \"Stop the Annihilation of the Salt River Wild Horses! http://t.co/wVobVVtXKg via @Change\"\n",
    "example = remove_url(example)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMTO7SEeQNdJ"
   },
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ujj63IOyPBad"
   },
   "outputs": [],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5wcEec-PX_S",
    "outputId": "e64b0d55-1b37-4d79-9983-4d33b360d7d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop the annihilation of the salt river wild horses!  via @change\n"
     ]
    }
   ],
   "source": [
    "example = convert_to_lowercase(example)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvaVbIX0T0i0"
   },
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OtpG4J8fTv4t"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1scD5QidT3Xd",
    "outputId": "c8d15741-a4bf-4379-a196-b8ac859589a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop the annihilation of the salt river wild horses  via change\n"
     ]
    }
   ],
   "source": [
    "example = remove_punctuation(example)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZga4Zv9QPl0"
   },
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nAy3iZ9dPeKA"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lX_jgReOP1q6",
    "outputId": "c41b609e-49d0-410b-d5da-77907d78fe9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop annihilation salt river wild horses via change\n"
     ]
    }
   ],
   "source": [
    "example = remove_stopwords(example)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "W8Cj9aVjU19g"
   },
   "outputs": [],
   "source": [
    "def apply_all_transformations(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['text'] = new_df['text'].apply(remove_url)\n",
    "    new_df['text'] = new_df['text'].apply(convert_to_lowercase)\n",
    "    new_df['text'] = new_df['text'].apply(remove_punctuation)\n",
    "    new_df['text'] = new_df['text'].apply(remove_stopwords)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEnMLqxw0hJr"
   },
   "source": [
    "## Preprocessed Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mK1Dtn9kwWjr"
   },
   "outputs": [],
   "source": [
    "new_train_df = apply_all_transformations(train_df)\n",
    "new_test_df = apply_all_transformations(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oV7K_mAhgk2l"
   },
   "source": [
    "# LSTM\n",
    "\n",
    "Make sure to use GPU backend on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2RCnayxRfk6Q"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WewBDBRHf01m",
    "outputId": "ef2cb6c7-19ed-45cf-9e02-f176c039eeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17978 unique tokens\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(new_train_df['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"Found {len(word_index)} unique tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDo4A1GrgHbF",
    "outputId": "fbcc0d39-09f2-4e54-aaa7-75f1fd968a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 100) (7613, 1)\n",
      "(3263, 100)\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenizer.texts_to_sequences(new_train_df['text'].values)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "Y_train = new_train_df['target'].values\n",
    "Y_train = Y_train.reshape((-1, 1))\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(new_test_df['text'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wMmmdyOgOjb",
    "outputId": "00b92fbc-bde5-417b-fa56-343c55d15918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,042,305\n",
      "Trainable params: 1,042,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmlPuH9KhbV0",
    "outputId": "e5d32304-ae61-4e04-c5f2-281c0fcb9b99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "96/96 [==============================] - 35s 28ms/step - loss: 0.6891 - accuracy: 0.5580 - val_loss: 0.6821 - val_accuracy: 0.5345\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 0.6675 - accuracy: 0.5862 - val_loss: 0.6731 - val_accuracy: 0.5345\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 0.6551 - accuracy: 0.5775 - val_loss: 0.6540 - val_accuracy: 0.5706\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 0.6219 - accuracy: 0.6758 - val_loss: 0.6040 - val_accuracy: 0.7242\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 0.5342 - accuracy: 0.7800 - val_loss: 0.5373 - val_accuracy: 0.7525\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 2s 21ms/step - loss: 0.4065 - accuracy: 0.8341 - val_loss: 0.4855 - val_accuracy: 0.7800\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 0.3321 - accuracy: 0.8691 - val_loss: 0.4814 - val_accuracy: 0.7735\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 0.2966 - accuracy: 0.8869 - val_loss: 0.4769 - val_accuracy: 0.7820\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 0.2624 - accuracy: 0.8983 - val_loss: 0.4906 - val_accuracy: 0.7820\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 2s 20ms/step - loss: 0.2303 - accuracy: 0.9180 - val_loss: 0.4963 - val_accuracy: 0.7754\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gaAkLUqEhz3B"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "test_preds = np.argmax(model.predict(X_test), axis=-1)\n",
    "df[\"id\"] = test_df[\"id\"]\n",
    "df[\"target\"] = test_preds\n",
    "df.to_csv(\"lstm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ_kc4Nx0Tvq"
   },
   "source": [
    "Not very good result when I submit to kaggle. Looks like the model is overfitting. LSTM might not be best for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "YlcvVk5qliAj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS6665 Final Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
